# Variant analysis recap:

*Performance Measurement* is essential for the business analysis, but we cannot rely on the median or average values, so we focus ourself on the distribution of variants, usually divided in 3 parts:

1. A few variants that describe a lot of cases
2. A good number of variants that describe a good number of cases
3. A lot of variants for a few cases

We focus ourself on the **part 1** or, maybe, on the **part 2**, but the **part 3** is near the useless.

The variant analysis is done on **event log** and we have different phases:

![image-20240325085837119](C:\Users\pietro\AppData\Roaming\Typora\typora-user-images\image-20240325085837119.png)

An event logs may contain **wrong or inaccurate information**. We consider it noise to be filtered out to improve our understanding of the process. 

There can be *errors in recording the events/cases* with activities no more relevant, with null time duration or with wrong timestamps.

And there can be recording of events/cases that are *incomplete*, even at attributes level (missing of timestamp, resource, cost...).

We can also *filtering irrilevant data*, so data that are not of interest for our analysis. For example we can divide the event logs in period of times because we are not interested on a specific time period :smile:.

We can even *filter for summarisation* to exclude information that we are not interested in. By simplifying our view on the process to improve our understanding we can relax the notion of varint speciying only:

- Start/End of activity
- Inclusion of specific activities (or grouping them)
- Cases with cycle-time between a range (so without including the real time)

We can also summarize for the *most frequent **activities** or **path***. 

> For example, focus on activities that represent the 90% of the total! We can learn a model from that

## Python:

```python
# importazione dati:
dF = pd.read_csv('https://raw.githubusercontent.com/paoloceravolo/BIS2022/main/Event%20Logs/CallCenterLog.csv',sep=',')
dF = pm4py.format_dataframe(dF, case_id='Case ID', activity_key='Activity', start_timestamp_key='Start Date', timestamp_key='End Date')

# Identificare le attivitá non frequenti:
dF.groupby('concept:name').size()

# Ora concentrati su quelle nulle:
dF.isnull().sum()

# Conversione in event_log e ottenimento varianti
event_log = pm4py.convert_to_event_log(dF)
variants = pm4py.get_variants(event_log)
# puoi anche usare la get_variants sul data frame direttamente
variants
plt.hist(variants)
plt.show()
```

> **Variants**:
>
> Identificano i vari passaggi tra le attivitá e il loro numero! Forse é ok togliere un certo numero di variants.

```python
# filtro tempi negativi
compute_case_duration(dF)
no_zero_duration = dF[dF['Duration'] > pd.Timedelta(0)]
no_zero_duration
```

> Fase di filtraggio finita dopo l'esclusione di certe attivitá di inizio. Vedi in vscode che hai fatto.
>
> Nella fase di filtraggio sarebbe anche bello individuare problemi di registrazione dei log, tipo quelli di durata negativa. Ma la loro registrazione errata dipende solo dal contesto.

```python
# ennesima prova dei valori medi, che sono delle merde
case_dur = filtered_log.groupby('Case ID')['Duration'].sum()
print('Mean duration', case_dur.mean())
print('Median duration', case_dur.median())
print('Mode duration', case_dur.mode().values[0])
print('STDev duration', case_dur.std())

import matplotlib.pyplot as plt
# va convertito...
case_dur = case_dur.dt.total_seconds().astype(int)
plt.hist(case_dur, bins=20, alpha=0.7)
plt.xlabel('Duration Mins')
plt.ylabel('Frequency')
plt.show()
# ancora una volta, la maggioranza dei casi ha una durata piccolissima
```

## Typical filter:

1. **Control-flow**
   1. Start/End activities
   2. Directly-follows
   3. Prefixes/Suffixes
   4. Case Size
2. **Time**
   1. TimeFrame
   2. Throughput
3. **Attibutes**:
   1. String attributes:
   2. Numeric Attributes

We can also filter for comparison to assess the performance of an event log. We can **compare variants, timeframes, departments, countries** but we need *statistical analysis* to be sure.

Or we can use **KPI** and more. See the slide to integrate this part.

# Comparative PM from theory to exe:

To assess *performance level* achivied by a variant/segment we need to compre it with a *reference level*.

So to assess the frequency of verification of a pattern in a variant/segment we need to compare it with a **reference frequency**.

We can compare stuff by an **objective defined by tho org** or with the **levels/frequencies obtained by other variants**.

![image-20240325113618709](C:\Users\pietro\AppData\Roaming\Typora\typora-user-images\image-20240325113618709.png)

We can see here that an objective level is already defined (by orgs) meanwhile comparing with levels or frequencies means to compare with the other variants.

> **CTE** -> Cycle Time Efficiency
>
> **V1** -> variant 1 (and so on)
>
> **repair**
>
> **tolerance**

![image-20240325113956242](./assets/image-20240325113956242.png)

But is our delta **significant?**

![image-20240325114058752](./assets/image-20240325114058752.png)

Each of these points have different requirements! Use slides to enforce them.

## Using frequency:

### Lift metrics:

We can use **bayesian tests**, for example, the [Lift Metrics](https://www.kdnuggets.com/2016/03/lift-analysis-data-scientist-secret-weapon.html) we used with Association Rules:

![image-20240325114710161](./assets/image-20240325114710161.png)

> $lift(x\rightarrow y)$ means that the observation of two variants divided by the product of two variants is in a range between 0 and infinte

### [Chi-square](https://www.simplilearn.com/tutorials/statistics-tutorial/chi-square-test) [helps on determine if two categorical vars are in relationship or not]:

The frequency of a categorical variable in a sample often needs to be compared with the frequency of a categorical variable in another sample.

So the **chi squared test** compares observed and expected value by calculating the expected as the average of the observed categories dimensioned based on the relative size of the group. But an image speaks more than words: 

![image-20240325115258825](./assets/image-20240325115258825.png)

> The Chi-Square test is a statistical procedure for **determining the difference between observed and expected [data**.](https://www.simplilearn.com/what-is-data-article) This test can also be used to **determine whether it correlates to the categorical variables in our data**. It **helps to find out whether a difference between two categorical variables is due to chance or a relationship between them.**

![image-20240325115544451](./assets/image-20240325115544451.png)

If the result is below 0.5% it means that the two vars are not mean to be in a relationship :disappointed:.

### [Central Tendency](https://www.statology.org/measures-central-tendency/) [for scalar values]:

It can verify if the difference is greater than the sum of std_devs.

![image-20240325115750269](./assets/image-20240325115750269.png)

> We have the average of cycle time activities and them std_devs, then we obtain the central tendency. If we obtain a value that is less than 1 we cannot say much...

Use this to determine **significant differences between segments used in variant analysis**!

> According to the source in the title a **measure of central tendency** is a single value that represents the center point of a dataset. As known as *central location*. 
>
> The common measures for this are **mean/median/mode**, despite that we can use the formula explained there to determine if the differences are significant or not.

### Simpon's Paradox:

Be careful while segmenting dataset, with one segmentation we obtain something, but with another we can throw away our knowledge...

> **Simpson's paradox** is a phenomenon in [probability](https://en.wikipedia.org/wiki/Probability) and [statistics](https://en.wikipedia.org/wiki/Statistics) in which a trend appears in several groups of data but disappears or reverses when the groups are combined

![image-20240325120750721](./assets/image-20240325120750721.png)

> By segmenting in 1 and 2, the difference is not so meaningful...
>
> By segmenting in 3 4 5 6 (by morning and past meridian for different operator) we have a difference between morning and afternoon that is important. The activities by O1 are more than O2 in the morning, but O2 works more on the afternoon...
>
> So based on different segmentation the results can be different. So **usually we segmented at least two times and compare those segmentations.**

> We can also observe the fix associated with suppliers:
> ![image-20240325121201816](./assets/image-20240325121201816.png)
> Apparently the supplier F1 is the one that requires more fixes, but...
>
> <img src="./assets/image-20240325121229784.png" alt="image-20240325121229784" style="zoom:67%;" />
>
> We can now observe that, usually, in the afternoon we have better performance, that is enforced by this segmentation:
>
> ![image-20240325121312501](./assets/image-20240325121312501.png)
>
> This show how in the morning the fixes occur more than in the afternoon, so is not fault of the suppliers F1, just see how F2 in the morning has 20% of fix, F3 10% and F1 14% (an average value...)